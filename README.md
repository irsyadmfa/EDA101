# EDA101

EDA overview:

Summary Statistics: Calculating basic summary statistics such as mean, median, mode, standard deviation, range, and quartiles for numerical variables. For categorical variables, frequency tables are created to understand the distribution of categories.

Data Visualization: Creating various types of visualizations to understand the data distribution and relationships. This includes histograms, box plots, scatter plots, bar charts, pie charts, heatmaps, and more. Visualization helps in identifying outliers, trends, patterns, and potential relationships between variables.

Handling Missing Values: Identifying missing values in the dataset and determining the best strategy to handle them. This may involve imputation techniques such as mean substitution, median substitution, mode substitution, or more advanced techniques like predictive modeling for imputation.

Data Cleaning: Detecting and addressing anomalies, errors, or inconsistencies in the data. This includes removing duplicates, correcting inaccuracies, and standardizing formats to ensure data quality.

Feature Engineering: Creating new features or transforming existing features to make them more suitable for modeling. This could involve encoding categorical variables, scaling numerical variables, creating interaction terms, or extracting relevant information from text or date fields.

Identifying Relationships: Exploring relationships between variables using correlation analysis, cross-tabulation, or other statistical techniques. Understanding these relationships helps in identifying predictors and understanding the underlying structure of the data.

Outlier Detection: Identifying outliers or anomalous data points that deviate significantly from the rest of the data. Outliers can impact model performance and need to be carefully examined to determine if they represent genuine observations or errors in data collection.

Dimensionality Reduction: Exploring techniques to reduce the dimensionality of the dataset while preserving important information. This could involve techniques like principal component analysis (PCA) or feature selection methods to remove irrelevant or redundant variables.

Overall, EDA is an iterative process that involves a combination of statistical analysis, visualization, and domain knowledge to gain a comprehensive understanding of the data. It helps in guiding subsequent steps in the data analysis pipeline, such as model selection, validation, and interpretation.
